{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163b8089",
   "metadata": {},
   "source": [
    "## Install required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8c5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain\n",
    "# pip install OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94887936",
   "metadata": {},
   "source": [
    "## Set API Key in local Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d7eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f137a9a",
   "metadata": {},
   "source": [
    "## Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce92d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "That's a difficult question to answer because beauty is subjective and can be found in many different forms. Ultimately, though, I believe the most beautiful thing in the world is the simple acts of kindness and compassion that people show each other every single day.\n",
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.9, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'best_of': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Temperature = Stability in next answer\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "text = \"What is most beautiful in this World?\"\n",
    "\n",
    "print(llm(text))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bc23d",
   "metadata": {},
   "source": [
    "## How to set Prompts Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cf5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "        input_variables = [\"product\" , \"Purpose\"],\n",
    "        template = \"What is good name for a company {product} and its {Purpose} is :\")\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "                input_variables = [\"product\"] , \n",
    "                template = \"Give me details on {product}.\"  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb888e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is good name for a company Infosys and its Share is :\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(product = \"Infosys\" , Purpose = \"Share\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98beab5",
   "metadata": {},
   "source": [
    "## Combine above two with LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810f635",
   "metadata": {},
   "source": [
    "### Here we use LLMChain to make chain withh the help of LLM and Prompt as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97982ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm , prompt = prompt)\n",
    "chain_1 = LLMChain(llm = llm , prompt = prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df712c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nInfy is an innovative and creative company name that comes from a combination of the words \"Infinity\" and \"Innovation.\" The message this name conveys is that of limitless potential, with a focus on creativity and forward-thinking solutions. The name is also versatile, working equally well for a start-up or an established company. Infy is a great choice for any business that strives to push the boundaries and remain on the cutting edge.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(product = \"Infy\"  , Purpose = \"Details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2322521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHDFC (Housing Development Finance Corporation Limited) is one of India’s largest and oldest private sector banking and financial services institutions. Established in 1977, it offers a range of banking and financial services including consumer banking, corporate banking, investment banking, private banking, insurance, asset management and wealth management. It has a large retail customer base with over 47 million customers, spread over 1,425 branches and 11,448 ATMs across 2,764 cities and towns in India. In addition to its banking activities, HDFC also provides a full suite of insurance services, including car, health, home, life and travel insurance products. It also offers personal, vehicle and business loans. HDFC is one of the most respected names in the Indian financial services sector and has been consistently ranked among the top-performing brands in the country.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1.run(product = \"HDFC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416ed75",
   "metadata": {},
   "source": [
    "## Memory Storing for Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93370900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi.. there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hi there! How can I help you?\n"
     ]
    }
   ],
   "source": [
    "from langchain import  ConversationChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "conversation = ConversationChain(llm = llm , verbose = True )\n",
    "\n",
    "output = conversation.predict(input = \"Hi.. there!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44775e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi.. there!\n",
      "AI:  Hi there! How can I help you?\n",
      "Human: All good , Just having convo with you...\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " That's great! It's always nice to chat with someone. What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input = \"All good , Just having convo with you...\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1821d",
   "metadata": {},
   "source": [
    "## Get Message Completions from a Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5910fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage , AIMessage , SystemMessage\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# chat([HumanMessage (content = \"Translate this sentance to Fresh , I love Programming.\")])\n",
    "chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78fcc340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Sure, here\\'s the translation:\\n\\n\"J\\'adore regarder des vidéos sur les affaires mondiales.\"', generation_info=None, message=AIMessage(content='Sure, here\\'s the translation:\\n\\n\"J\\'adore regarder des vidéos sur les affaires mondiales.\"', additional_kwargs={}))], [ChatGeneration(text='我喜欢看中文视频。', generation_info=None, message=AIMessage(content='我喜欢看中文视频。', additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 57, 'completion_tokens': 34, 'total_tokens': 91}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_msg = [\n",
    "    [ SystemMessage(content= \"Your much helpful AI Bot\") , \n",
    "    HumanMessage (content= \"Kindly translate , I love to watch World affairs Videos\")] ,\n",
    "    \n",
    "    [SystemMessage(content= \"Thanks for Helping me\") , \n",
    "    HumanMessage(content= \"convert ,  I love to watch Videos  in chinese\")]\n",
    "    \n",
    "]\n",
    "\n",
    "result = chat.generate(both_msg)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99c29665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_usage', 'model_name'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f29dbc2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 55, 'completion_tokens': 68, 'total_tokens': 123}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output['token_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ccda9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output['model_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733627a3",
   "metadata": {},
   "source": [
    "## Chat Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db0eba8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Je suis en train d'atteindre mon objectif.\", additional_kwargs={})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate , SystemMessagePromptTemplate , ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature = 0.5)\n",
    "\n",
    "system_template = \"Your very helpful template that convert {input_language} to {output_language}.\"\n",
    "sytem_msg_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([sytem_msg_prompt , human_msg_prompt])\n",
    "\n",
    "chat(chat_prompt.format_prompt(input_language = 'English' , output_language = 'French' , text = \"I am toward my goal\").to_messages())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542d128",
   "metadata": {},
   "source": [
    "## Chains with Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae672f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime travailler sur des tâches stimulantes dans le confort...\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import SystemMessagePromptTemplate , HumanMessagePromptTemplate , PromptTemplate , ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature = 0.4)\n",
    "\n",
    "template = \"Your helpful assistant , Kindly convert {input_lang} to {output_lang}\"\n",
    "sys_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template = \"{text}\"\n",
    "humna_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([sys_prompt , humna_prompt])\n",
    "\n",
    "chain = LLMChain(llm = chat , prompt = chat_prompt)\n",
    "chain.run(input_lang = \"English\" , output_lang = \"French\" , text = \"I love Changllenging work in my comfort...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc11e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
